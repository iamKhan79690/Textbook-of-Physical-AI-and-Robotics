"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[356],{4262:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"Gazebo-Simulation/adding-sensors","title":"Lesson 5: Adding Sensors","description":"Equip robots with cameras, LiDAR, and IMU sensors for perception","source":"@site/docs/03-Gazebo-Simulation/05-adding-sensors.md","sourceDirName":"03-Gazebo-Simulation","slug":"/Gazebo-Simulation/adding-sensors","permalink":"/docs/Gazebo-Simulation/adding-sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/ai-book/tree/main/docs/03-Gazebo-Simulation/05-adding-sensors.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"title":"Lesson 5: Adding Sensors","description":"Equip robots with cameras, LiDAR, and IMU sensors for perception"},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 4: Physics Simulation Tuning","permalink":"/docs/Gazebo-Simulation/physics-simulation"},"next":{"title":"Lesson 6: Processing Sensor Data","permalink":"/docs/Gazebo-Simulation/processing-sensors"}}');var i=s(4848),l=s(8453);const a={sidebar_position:6,title:"Lesson 5: Adding Sensors",description:"Equip robots with cameras, LiDAR, and IMU sensors for perception"},o="Lesson 5: Adding Sensors (75 minutes)",t={},c=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Core Concepts (8 Total)",id:"core-concepts-8-total",level:2},{value:"1. Gazebo Sensor Plugins",id:"1-gazebo-sensor-plugins",level:3},{value:"2. Camera Intrinsics",id:"2-camera-intrinsics",level:3},{value:"3. LiDAR Beam Model",id:"3-lidar-beam-model",level:3},{value:"4. IMU (Inertial Measurement Unit)",id:"4-imu-inertial-measurement-unit",level:3},{value:"5. Sensor Placement",id:"5-sensor-placement",level:3},{value:"6. ROS 2 Topic Mapping",id:"6-ros-2-topic-mapping",level:3},{value:"7. Noise Models",id:"7-noise-models",level:3},{value:"8. Sensor Refresh Rates",id:"8-sensor-refresh-rates",level:3},{value:"Layer 1: Manual Exercise - Add Sensors to URDF",id:"layer-1-manual-exercise---add-sensors-to-urdf",level:2},{value:"Exercise Steps:",id:"exercise-steps",level:3},{value:"Code Example: Robot with All Sensors",id:"code-example-robot-with-all-sensors",level:2},{value:"Layer 2: AI Collaboration Notes",id:"layer-2-ai-collaboration-notes",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Problem: &quot;Plugin not found: libgazebo_ros_camera.so&quot;",id:"problem-plugin-not-found-libgazebo_ros_cameraso",level:3},{value:"Problem: Sensor topics don&#39;t appear in <code>ros2 topic list</code>",id:"problem-sensor-topics-dont-appear-in-ros2-topic-list",level:3},{value:"Problem: Camera image is black/empty",id:"problem-camera-image-is-blackempty",level:3},{value:"Problem: LiDAR returns all zeros (no range data)",id:"problem-lidar-returns-all-zeros-no-range-data",level:3},{value:"Problem: IMU data looks unrealistic (huge accelerations)",id:"problem-imu-data-looks-unrealistic-huge-accelerations",level:3},{value:"Self-Assessment Checklist",id:"self-assessment-checklist",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Lesson",id:"next-lesson",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lesson-5-adding-sensors-75-minutes",children:"Lesson 5: Adding Sensors (75 minutes)"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, you will:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Understand sensor plugin architecture in Gazebo"}),"\n",(0,i.jsx)(n.li,{children:"Add camera, LiDAR, and IMU sensors to robot URDFs"}),"\n",(0,i.jsx)(n.li,{children:"Configure sensor intrinsics (focal length, field of view, noise)"}),"\n",(0,i.jsx)(n.li,{children:"Verify sensors publish to correct ROS 2 topics"}),"\n",(0,i.jsx)(n.li,{children:"Visualize sensor data in RViz"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Lesson 4 completed (physics-tuned robot)"}),"\n",(0,i.jsx)(n.li,{children:"ROS 2 sensor_msgs understanding"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"core-concepts-8-total",children:"Core Concepts (8 Total)"}),"\n",(0,i.jsx)(n.h3,{id:"1-gazebo-sensor-plugins",children:"1. Gazebo Sensor Plugins"}),"\n",(0,i.jsx)(n.p,{children:"Plugins bridge Gazebo simulation and ROS 2:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"gazebo_ros_camera"}),": Simulates camera with optical distortion"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"gazebo_ros_lidar"}),": Simulates 2D/3D LiDAR with ray casting"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"gazebo_ros_imu"}),": Simulates inertial measurement unit"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Each plugin:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Reads simulation state at update_rate"}),"\n",(0,i.jsx)(n.li,{children:"Publishes ROS 2 messages"}),"\n",(0,i.jsx)(n.li,{children:"Can add noise models for realism"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-camera-intrinsics",children:"2. Camera Intrinsics"}),"\n",(0,i.jsx)(n.p,{children:"Camera parameters that define how images are formed:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Focal length"})," (fx, fy): Lens zoom (pixels)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Principal point"})," (cx, cy): Center of image (pixels)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Distortion"}),": Barrel/pincushion distortion coefficients"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Field of view"}),": Horizontal and vertical angle (radians)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Image resolution"}),": Width \xd7 height in pixels"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Typical values:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"fx = fy = 500 pixels  (moderate zoom)\r\ncx = width/2, cy = height/2\r\nfov = 60-90 degrees\r\nresolution = 640\xd7480 or 1280\xd7960\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-lidar-beam-model",children:"3. LiDAR Beam Model"}),"\n",(0,i.jsx)(n.p,{children:"LiDAR simulates laser rangefinder:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Beam count"}),": 1 (single beam) to 360+ (spinning laser)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Angular resolution"}),": Degrees between consecutive beams"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Range"}),": Min/max distance scannable (0.1 m to 100+ m)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Noise model"}),": Gaussian noise on range measurements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Update rate"}),": Scans per second (typically 10-40 Hz)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"4-imu-inertial-measurement-unit",children:"4. IMU (Inertial Measurement Unit)"}),"\n",(0,i.jsx)(n.p,{children:"Measures acceleration and angular velocity:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Accelerometer"}),": Linear acceleration in X, Y, Z"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gyroscope"}),": Angular velocity around X, Y, Z axes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Noise models"}),": Gaussian noise on each sensor"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Update rate"}),": Measurements per second (typically 100+ Hz)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"5-sensor-placement",children:"5. Sensor Placement"}),"\n",(0,i.jsx)(n.p,{children:"Sensor frame attachment:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fixed joints"})," connect sensor links to robot body"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Frame ID"}),": ROS 2 TF frame (e.g., ",(0,i.jsx)(n.code,{children:"camera_link"}),", ",(0,i.jsx)(n.code,{children:"lidar_link"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Origin"}),": Offset from parent link (xyz and rotation)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Example:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<joint name="camera_mount_joint" type="fixed">\r\n  <parent link="base_link"/>\r\n  <child link="camera_link"/>\r\n  <origin xyz="0.1 0 0.05" rpy="0 0 0"/>  \x3c!-- 10cm forward, 5cm up --\x3e\r\n</joint>\n'})}),"\n",(0,i.jsx)(n.h3,{id:"6-ros-2-topic-mapping",children:"6. ROS 2 Topic Mapping"}),"\n",(0,i.jsx)(n.p,{children:"Plugins map sensor data to ROS 2 topics:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Camera"}),": ",(0,i.jsx)(n.code,{children:"/camera/image_raw"})," (sensor_msgs/Image)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LiDAR"}),": ",(0,i.jsx)(n.code,{children:"/scan"})," (sensor_msgs/LaserScan)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IMU"}),": ",(0,i.jsx)(n.code,{children:"/imu/data"})," (sensor_msgs/Imu)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Custom namespacing:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<ros>\r\n  <namespace>/robot/sensors</namespace>  \x3c!-- Changes to /robot/sensors/camera/image_raw --\x3e\r\n</ros>\n"})}),"\n",(0,i.jsx)(n.h3,{id:"7-noise-models",children:"7. Noise Models"}),"\n",(0,i.jsx)(n.p,{children:"Realistic sensors have noise:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gaussian"}),": Random noise with mean 0, standard deviation \u03c3"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Update rate effects"}),": Lower update rates = less frequent measurements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Quantization"}),": Measurement precision (e.g., 1 mm for LiDAR)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"8-sensor-refresh-rates",children:"8. Sensor Refresh Rates"}),"\n",(0,i.jsx)(n.p,{children:"Critical for timing:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Camera"}),": 10-30 Hz (human visual perception)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LiDAR"}),": 10-40 Hz (navigation planning)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"IMU"}),": 100-200 Hz (high-speed control feedback)"]}),"\n",(0,i.jsx)(n.li,{children:"Must coordinate in ROS 2 subscribers (message_filters for synchronization)"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"layer-1-manual-exercise---add-sensors-to-urdf",children:"Layer 1: Manual Exercise - Add Sensors to URDF"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-steps",children:"Exercise Steps:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Create camera link"})," (small sphere at front):"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<link name="camera_link">\r\n  <inertial><mass value="0.05"/><inertia ixx="0.001" ixy="0" ixz="0" iyy="0.001" iyz="0" izz="0.001"/></inertial>\r\n  <visual><geometry><sphere radius="0.02"/></geometry></visual>\r\n  <collision><geometry><sphere radius="0.02"/></geometry></collision>\r\n</link>\n'})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mount camera on base"}),":"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<joint name="camera_joint" type="fixed">\r\n  <parent link="base_link"/>\r\n  <child link="camera_link"/>\r\n  <origin xyz="0.1 0 0.05" rpy="0 0 0"/>  \x3c!-- 10cm forward, 5cm up --\x3e\r\n</joint>\n'})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Add camera plugin"}),":"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<gazebo reference="camera_link">\r\n  <sensor type="camera" name="camera_sensor">\r\n    <update_rate>30</update_rate>\r\n    <camera>\r\n      <horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees --\x3e\r\n      <image><width>640</width><height>480</height></image>\r\n      <clip><near>0.1</near><far>100</far></clip>\r\n    </camera>\r\n    <plugin name="camera_plugin" filename="libgazebo_ros_camera.so">\r\n      <ros><namespace>/camera</namespace></ros>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"code-example-robot-with-all-sensors",children:"Code Example: Robot with All Sensors"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"File"}),": ",(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-05/robot-with-all-sensors.urdf"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<robot name="sensor_equipped_robot">\r\n  \x3c!-- Simulation environment: Gazebo 11+ --\x3e\r\n\r\n  \x3c!-- Base Link (from previous lessons) --\x3e\r\n  <link name="base_link">\r\n    <inertial>\r\n      <mass value="5.0"/>\r\n      <inertia ixx="0.5" ixy="0" ixz="0"\r\n               iyy="0.5" iyz="0" izz="0.4"/>\r\n    </inertial>\r\n    <visual>\r\n      <geometry><box size="0.2 0.15 0.1"/></geometry>\r\n      <material name="base_color"><color rgba="0.7 0.7 0.7 1"/></material>\r\n    </visual>\r\n    <collision>\r\n      <geometry><box size="0.2 0.15 0.1"/></geometry>\r\n    </collision>\r\n  </link>\r\n\r\n  \x3c!-- Wheels (omitted for brevity, same as lesson 3) --\x3e\r\n\r\n  \x3c!-- Camera Link --\x3e\r\n  <link name="camera_link">\r\n    <inertial>\r\n      <mass value="0.05"/>\r\n      <inertia ixx="0.001" ixy="0" ixz="0"\r\n               iyy="0.001" iyz="0" izz="0.001"/>\r\n    </inertial>\r\n    <visual>\r\n      <geometry><box size="0.05 0.05 0.03"/></geometry>\r\n      <material name="camera_material"><color rgba="0.3 0.3 0.3 1"/></material>\r\n    </visual>\r\n    <collision>\r\n      <geometry><box size="0.05 0.05 0.03"/></geometry>\r\n    </collision>\r\n  </link>\r\n\r\n  \x3c!-- LiDAR Link --\x3e\r\n  <link name="lidar_link">\r\n    <inertial>\r\n      <mass value="0.1"/>\r\n      <inertia ixx="0.001" ixy="0" ixz="0"\r\n               iyy="0.001" iyz="0" izz="0.001"/>\r\n    </inertial>\r\n    <visual>\r\n      <geometry><cylinder radius="0.03" length="0.05"/></geometry>\r\n      <material name="lidar_material"><color rgba="0.2 0.2 0.2 1"/></material>\r\n    </visual>\r\n    <collision>\r\n      <geometry><cylinder radius="0.03" length="0.05"/></geometry>\r\n    </collision>\r\n  </link>\r\n\r\n  \x3c!-- IMU Link --\x3e\r\n  <link name="imu_link">\r\n    <inertial>\r\n      <mass value="0.01"/>\r\n      <inertia ixx="0.0001" ixy="0" ixz="0"\r\n               iyy="0.0001" iyz="0" izz="0.0001"/>\r\n    </inertial>\r\n    <visual>\r\n      <geometry><box size="0.02 0.02 0.02"/></geometry>\r\n      <material name="imu_material"><color rgba="0.5 0.5 0.5 1"/></material>\r\n    </visual>\r\n    <collision>\r\n      <geometry><box size="0.02 0.02 0.02"/></geometry>\r\n    </collision>\r\n  </link>\r\n\r\n  \x3c!-- Camera Joint --\x3e\r\n  <joint name="camera_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="camera_link"/>\r\n    <origin xyz="0.1 0 0.05" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n  \x3c!-- LiDAR Joint --\x3e\r\n  <joint name="lidar_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="lidar_link"/>\r\n    <origin xyz="0 0 0.1" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n  \x3c!-- IMU Joint --\x3e\r\n  <joint name="imu_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="imu_link"/>\r\n    <origin xyz="0 0 0" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n  \x3c!-- Gazebo Sensor Plugins --\x3e\r\n  <gazebo reference="camera_link">\r\n    <sensor type="camera" name="camera_sensor">\r\n      <update_rate>30</update_rate>\r\n      <camera>\r\n        <horizontal_fov>1.047</horizontal_fov>\r\n        <image><width>640</width><height>480</height></image>\r\n        <clip><near>0.1</near><far>100</far></clip>\r\n        <distortion>\r\n          <k1>0.0</k1>\r\n          <k2>0.0</k2>\r\n          <k3>0.0</k3>\r\n          <p1>0.0</p1>\r\n          <p2>0.0</p2>\r\n        </distortion>\r\n      </camera>\r\n      <plugin name="camera_plugin" filename="libgazebo_ros_camera.so">\r\n        <ros><namespace>/camera</namespace></ros>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n  <gazebo reference="lidar_link">\r\n    <sensor type="ray" name="lidar_sensor">\r\n      <update_rate>10</update_rate>\r\n      <ray>\r\n        <scan>\r\n          <horizontal>\r\n            <samples>360</samples>\r\n            <resolution>1</resolution>\r\n            <min_angle>-3.141592654</min_angle>\r\n            <max_angle>3.141592654</max_angle>\r\n          </horizontal>\r\n        </scan>\r\n        <range>\r\n          <min>0.1</min>\r\n          <max>30.0</max>\r\n          <resolution>0.01</resolution>\r\n        </range>\r\n        <noise>\r\n          <type>gaussian</type>\r\n          <mean>0.0</mean>\r\n          <stddev>0.01</stddev>\r\n        </noise>\r\n      </ray>\r\n      <plugin name="lidar_plugin" filename="libgazebo_ros_lidar.so">\r\n        <ros><namespace>/lidar</namespace></ros>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n  <gazebo reference="imu_link">\r\n    <sensor type="imu" name="imu_sensor">\r\n      <update_rate>100</update_rate>\r\n      <imu>\r\n        <noise>\r\n          <type>gaussian</type>\r\n          <rate>\r\n            <mean>0.0</mean>\r\n            <stddev>0.01</stddev>\r\n          </rate>\r\n          <accel>\r\n            <mean>0.0</mean>\r\n            <stddev>0.1</stddev>\r\n          </accel>\r\n        </noise>\r\n      </imu>\r\n      <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\r\n        <ros><namespace>/imu</namespace></ros>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n</robot>\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"layer-2-ai-collaboration-notes",children:"Layer 2: AI Collaboration Notes"}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udcac ",(0,i.jsx)(n.strong,{children:"Prompt 1"}),': "Why do I need both camera and LiDAR? What\'s the difference?"']}),"\n",(0,i.jsx)(n.p,{children:"Claude explains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Camera"}),": Sees color/texture (needs lighting, detailed visual processing)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LiDAR"}),": Measures distance to objects (works in dark, gives 3D point cloud)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Camera best for"}),": Object recognition, visual features, human-readable imagery"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LiDAR best for"}),": Obstacle detection, navigation, range measurements"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udcac ",(0,i.jsx)(n.strong,{children:"Prompt 2"}),": \"My sensor is publishing but the topic appears in 'rostopic list' but no messages arrive. What's wrong?\""]}),"\n",(0,i.jsx)(n.p,{children:"Claude explains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Plugin loaded but not publishing messages"}),"\n",(0,i.jsx)(n.li,{children:"Check topic name matches between URDF and subscriber"}),"\n",(0,i.jsx)(n.li,{children:"Verify update_rate > 0 (not paused)"}),"\n",(0,i.jsx)(n.li,{children:"Check ROS_DOMAIN_ID matches between publisher and subscriber"}),"\n",(0,i.jsxs)(n.li,{children:["Use ",(0,i.jsx)(n.code,{children:"ros2 topic hz /topic_name"})," to verify message rate"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"problem-plugin-not-found-libgazebo_ros_cameraso",children:'Problem: "Plugin not found: libgazebo_ros_camera.so"'}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": gazebo-ros plugins not installed\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt install ros-humble-gazebo-ros-pkgs\n"})}),"\n",(0,i.jsxs)(n.h3,{id:"problem-sensor-topics-dont-appear-in-ros2-topic-list",children:["Problem: Sensor topics don't appear in ",(0,i.jsx)(n.code,{children:"ros2 topic list"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Topic namespace wrong or plugin not initialized\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Check ",(0,i.jsx)(n.code,{children:"<namespace>"})," in plugin configuration"]}),"\n",(0,i.jsxs)(n.li,{children:["Verify Gazebo runs with ROS 2 support: ",(0,i.jsx)(n.code,{children:"gazebo -s libgazebo_ros_init.so"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"problem-camera-image-is-blackempty",children:"Problem: Camera image is black/empty"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Camera position wrong or object too close/far from camera\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"\x3c!-- Adjust focal length and clip planes --\x3e\r\n<horizontal_fov>1.047</horizontal_fov>  \x3c!-- 60 degrees FOV --\x3e\r\n<clip><near>0.1</near><far>100</far></clip>\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-lidar-returns-all-zeros-no-range-data",children:"Problem: LiDAR returns all zeros (no range data)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": No objects in range or ray direction wrong\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Verify objects exist in simulation"}),"\n",(0,i.jsx)(n.li,{children:"Check horizontal_fov covers 360 degrees"}),"\n",(0,i.jsx)(n.li,{children:"Ensure min/max range reasonable"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"problem-imu-data-looks-unrealistic-huge-accelerations",children:"Problem: IMU data looks unrealistic (huge accelerations)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Noise model too aggressive or gravity not applied\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:"<stddev>0.1</stddev>  \x3c!-- Reduce from 1.0 to 0.1 --\x3e\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"self-assessment-checklist",children:"Self-Assessment Checklist"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I understand the role of Gazebo sensor plugins"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I've added camera, LiDAR, and IMU sensors to a robot URDF"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","My sensors appear as links/joints in the kinematic tree"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Each sensor publishes to the correct ROS 2 topic"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I can configure sensor intrinsics (FOV, resolution, noise)"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I've verified sensor data in RViz (camera image, point cloud, IMU)"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sensors are links + plugins"}),": Physical part (link) + simulation (plugin)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Fixed joints attach sensors"}),": Immobilize sensors relative to robot"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Topic namespacing prevents collisions"}),": Multiple robots can have ",(0,i.jsx)(n.code,{children:"/camera/image_raw"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Update rates matter"}),": Sync sensors with ROS 2 message_filters"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Noise models add realism"}),": Gazebo can simulate sensor imperfections"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"next-lesson",children:"Next Lesson"}),"\n",(0,i.jsx)(n.p,{children:"In Lesson 6, you'll write ROS 2 nodes to process sensor data and extract meaningful information."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"./lesson-06-processing-sensors.md",children:"Go to Lesson 6: Processing Sensor Data \u2192"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Lesson Status"}),": Complete with sensor plugin overview, full multi-sensor robot URDF, and sensor configuration guide."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Duration"}),": 75 minutes (including RViz sensor visualization)"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Files Created"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-05/robot-with-camera.urdf"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-05/robot-with-lidar.urdf"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-05/robot-with-imu.urdf"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-05/robot-with-all-sensors.urdf"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Concepts Covered"}),": 8 (sensor plugins, camera intrinsics, LiDAR beam model, IMU, sensor placement, ROS 2 topic mapping, noise models, update rates)"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>o});var r=s(6540);const i={},l=r.createContext(i);function a(e){const n=r.useContext(l);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(l.Provider,{value:n},e.children)}}}]);