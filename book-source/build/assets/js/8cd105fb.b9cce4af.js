"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[460],{8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>o});var s=r(6540);const i={},a=s.createContext(i);function l(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(a.Provider,{value:n},e.children)}},9442:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>s,toc:()=>t});const s=JSON.parse('{"id":"Gazebo-Simulation/processing-sensors","title":"Lesson 6: Processing Sensor Data","description":"Write ROS 2 subscribers to process camera, LiDAR, and IMU data in real-time","source":"@site/docs/03-Gazebo-Simulation/06-processing-sensors.md","sourceDirName":"03-Gazebo-Simulation","slug":"/Gazebo-Simulation/processing-sensors","permalink":"/docs/Gazebo-Simulation/processing-sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/ai-book/tree/main/docs/03-Gazebo-Simulation/06-processing-sensors.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Lesson 6: Processing Sensor Data","description":"Write ROS 2 subscribers to process camera, LiDAR, and IMU data in real-time"},"sidebar":"tutorialSidebar","previous":{"title":"Lesson 5: Adding Sensors","permalink":"/docs/Gazebo-Simulation/adding-sensors"},"next":{"title":"Lesson 7: Gazebo-ROS 2 Integration","permalink":"/docs/Gazebo-Simulation/gazebo-ros2-integration"}}');var i=r(4848),a=r(8453);const l={sidebar_position:7,title:"Lesson 6: Processing Sensor Data",description:"Write ROS 2 subscribers to process camera, LiDAR, and IMU data in real-time"},o="Lesson 6: Processing Sensor Data (75 minutes)",c={},t=[{value:"Learning Outcomes",id:"learning-outcomes",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Core Concepts (8 Total)",id:"core-concepts-8-total",level:2},{value:"1. Image Subscribers",id:"1-image-subscribers",level:3},{value:"2. LaserScan Subscribers",id:"2-laserscan-subscribers",level:3},{value:"3. IMU Subscribers",id:"3-imu-subscribers",level:3},{value:"4. cv_bridge (Image Conversion)",id:"4-cv_bridge-image-conversion",level:3},{value:"5. Message Filtering (Time Sync)",id:"5-message-filtering-time-sync",level:3},{value:"6. Obstacle Detection",id:"6-obstacle-detection",level:3},{value:"7. Edge Detection (OpenCV)",id:"7-edge-detection-opencv",level:3},{value:"8. Visualization in RViz",id:"8-visualization-in-rviz",level:3},{value:"Layer 1: Manual Exercise",id:"layer-1-manual-exercise",level:2},{value:"Exercise: Process Camera Image with Edge Detection",id:"exercise-process-camera-image-with-edge-detection",level:3},{value:"Code Examples: Sensor Subscribers",id:"code-examples-sensor-subscribers",level:2},{value:"Camera Image Subscriber with Edge Detection",id:"camera-image-subscriber-with-edge-detection",level:3},{value:"LaserScan Subscriber with Obstacle Detection",id:"laserscan-subscriber-with-obstacle-detection",level:3},{value:"IMU Subscriber",id:"imu-subscriber",level:3},{value:"Multi-Sensor Fusion with Time Synchronization",id:"multi-sensor-fusion-with-time-synchronization",level:3},{value:"Layer 2: AI Collaboration Notes",id:"layer-2-ai-collaboration-notes",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Problem: &quot;cv_bridge not found&quot;",id:"problem-cv_bridge-not-found",level:3},{value:"Problem: Image callback receives empty image",id:"problem-image-callback-receives-empty-image",level:3},{value:"Problem: LaserScan contains all inf values",id:"problem-laserscan-contains-all-inf-values",level:3},{value:"Problem: IMU data looks wrong (huge random values)",id:"problem-imu-data-looks-wrong-huge-random-values",level:3},{value:"Problem: Synchronized callback never fires",id:"problem-synchronized-callback-never-fires",level:3},{value:"Self-Assessment Checklist",id:"self-assessment-checklist",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Lesson",id:"next-lesson",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"lesson-6-processing-sensor-data-75-minutes",children:"Lesson 6: Processing Sensor Data (75 minutes)"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-outcomes",children:"Learning Outcomes"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this lesson, you will:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Write ROS 2 subscriber nodes for camera, LiDAR, and IMU data"}),"\n",(0,i.jsx)(n.li,{children:"Convert ROS 2 Image messages to OpenCV format"}),"\n",(0,i.jsx)(n.li,{children:"Extract obstacle distances from LaserScan data"}),"\n",(0,i.jsx)(n.li,{children:"Interpret IMU acceleration and rotation values"}),"\n",(0,i.jsx)(n.li,{children:"Synchronize multi-sensor data using message_filters"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Lesson 5 completed (sensors added to robot)"}),"\n",(0,i.jsx)(n.li,{children:"Chapter 1 understanding of ROS 2 subscribers"}),"\n",(0,i.jsx)(n.li,{children:"Comfortable with Python 3.10+"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Install dependencies"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt install python3-cv-bridge python3-opencv ros-humble-message-filters\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"core-concepts-8-total",children:"Core Concepts (8 Total)"}),"\n",(0,i.jsx)(n.h3,{id:"1-image-subscribers",children:"1. Image Subscribers"}),"\n",(0,i.jsxs)(n.p,{children:["ROS 2 Camera images are ",(0,i.jsx)(n.code,{children:"sensor_msgs/Image"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"encoding"}),": Pixel format (",(0,i.jsx)(n.code,{children:"rgb8"}),", ",(0,i.jsx)(n.code,{children:"bgr8"}),", ",(0,i.jsx)(n.code,{children:"mono8"}),", etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"width, height"}),": Image dimensions in pixels"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"data"}),": Raw pixel bytes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"header.frame_id"}),": Camera optical frame"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Typical workflow:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Subscribe to ",(0,i.jsx)(n.code,{children:"/camera/image_raw"})]}),"\n",(0,i.jsx)(n.li,{children:"Convert Image \u2192 OpenCV Mat (using cv_bridge)"}),"\n",(0,i.jsx)(n.li,{children:"Process with OpenCV (edge detection, feature extraction)"}),"\n",(0,i.jsx)(n.li,{children:"Publish results back to ROS 2"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"2-laserscan-subscribers",children:"2. LaserScan Subscribers"}),"\n",(0,i.jsxs)(n.p,{children:["ROS 2 LiDAR scans are ",(0,i.jsx)(n.code,{children:"sensor_msgs/LaserScan"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"angle_min, angle_max"}),": Scan coverage (radians, typically -\u03c0 to \u03c0)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"angle_increment"}),": Radians between consecutive beams"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ranges"}),": Array of distances (in meters)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"intensities"}),": Optional reflectivity per beam"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"header.stamp"}),": Measurement timestamp"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Example interpretation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for i, range_val in enumerate(msg.ranges):\r\n    angle = msg.angle_min + i * msg.angle_increment\r\n    # (angle, range_val) = one measurement point\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-imu-subscribers",children:"3. IMU Subscribers"}),"\n",(0,i.jsxs)(n.p,{children:["ROS 2 IMU data is ",(0,i.jsx)(n.code,{children:"sensor_msgs/Imu"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"linear_acceleration"}),": 3D acceleration vector (m/s\xb2)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"x, y, z"})," components in IMU frame"]}),"\n",(0,i.jsx)(n.li,{children:"Includes gravity (9.81 m/s\xb2 downward if stationary)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"angular_velocity"}),": 3D rotation rate (rad/s)","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"x, y, z"})," components (roll, pitch, yaw rates)"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"orientation"}),": Quaternion (if IMU can estimate attitude)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Example interpretation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"accel_magnitude = sqrt(ax\xb2 + ay\xb2 + az\xb2)  # Total acceleration\n"})}),"\n",(0,i.jsx)(n.h3,{id:"4-cv_bridge-image-conversion",children:"4. cv_bridge (Image Conversion)"}),"\n",(0,i.jsx)(n.p,{children:"Converts between ROS 2 Image and OpenCV Mat:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from cv_bridge import CvBridge\r\nbridge = CvBridge()\r\n\r\n# Image \u2192 OpenCV\r\ncv_image = bridge.imgmsg_to_cv2(image_msg, "bgr8")\r\n\r\n# OpenCV \u2192 Image (to publish)\r\nimage_msg = bridge.cv2_to_imgmsg(cv_image, "bgr8")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"5-message-filtering-time-sync",children:"5. Message Filtering (Time Sync)"}),"\n",(0,i.jsx)(n.p,{children:"Synchronize multiple sensor streams (camera + LiDAR + IMU):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from message_filters import Subscriber, ApproximateTimeSynchronizer\r\n\r\nimage_sub = Subscriber(node, Image, '/camera/image_raw')\r\nscan_sub = Subscriber(node, LaserScan, '/scan')\r\nimu_sub = Subscriber(node, Imu, '/imu/data')\r\n\r\n# Synchronize messages within 100ms time window\r\nsync = ApproximateTimeSynchronizer([image_sub, scan_sub, imu_sub], 10, 0.1)\r\nsync.registerCallback(synchronized_callback)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"6-obstacle-detection",children:"6. Obstacle Detection"}),"\n",(0,i.jsx)(n.p,{children:"Extract obstacles from LaserScan:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Find closest obstacle\r\nmin_range = min(msg.ranges)\r\nmin_index = msg.ranges.index(min_range)\r\nobstacle_angle = msg.angle_min + min_index * msg.angle_increment\r\n\r\n# All obstacles within threshold\r\nobstacles = [(i, r) for i, r in enumerate(msg.ranges) if r < 0.5]\n"})}),"\n",(0,i.jsx)(n.h3,{id:"7-edge-detection-opencv",children:"7. Edge Detection (OpenCV)"}),"\n",(0,i.jsx)(n.p,{children:"Common image processing for camera data:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import cv2\r\n# Canny edge detection\r\nedges = cv2.Canny(cv_image, 100, 200)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"8-visualization-in-rviz",children:"8. Visualization in RViz"}),"\n",(0,i.jsx)(n.p,{children:"Processed data can be published as:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Image topic"}),": Reprocess and republish edited images"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MarkerArray"}),": 3D visual overlays in RViz"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PointCloud2"}),": 3D point clouds from LiDAR"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Twist"}),": Control commands based on sensor input"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"layer-1-manual-exercise",children:"Layer 1: Manual Exercise"}),"\n",(0,i.jsx)(n.h3,{id:"exercise-process-camera-image-with-edge-detection",children:"Exercise: Process Camera Image with Edge Detection"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Launch Gazebo with sensor-equipped robot (from Lesson 5)"}),"\n",(0,i.jsxs)(n.li,{children:["In RViz, add ",(0,i.jsx)(n.strong,{children:"Image"})," display for ",(0,i.jsx)(n.code,{children:"/camera/image_raw"})]}),"\n",(0,i.jsx)(n.li,{children:"Observe raw camera image"}),"\n",(0,i.jsx)(n.li,{children:"Run image processor script (see below)"}),"\n",(0,i.jsxs)(n.li,{children:["Add second ",(0,i.jsx)(n.strong,{children:"Image"})," display for ",(0,i.jsx)(n.code,{children:"/camera/edges"})]}),"\n",(0,i.jsx)(n.li,{children:"See edge-detected image appear"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"code-examples-sensor-subscribers",children:"Code Examples: Sensor Subscribers"}),"\n",(0,i.jsx)(n.h3,{id:"camera-image-subscriber-with-edge-detection",children:"Camera Image Subscriber with Edge Detection"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"File"}),": ",(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/camera_subscriber.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\"\"\"\r\nCamera image subscriber with edge detection\r\nSimulation environment: Gazebo 11+\r\n\"\"\"\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\n\r\nclass ImageProcessorNode(Node):\r\n    def __init__(self):\r\n        super().__init__('image_processor')\r\n        self.bridge = CvBridge()\r\n\r\n        # Subscribe to camera image\r\n        self.image_sub = self.create_subscription(\r\n            Image,\r\n            '/camera/image_raw',\r\n            self.image_callback,\r\n            10)\r\n\r\n        # Publish processed edges\r\n        self.edges_pub = self.create_publisher(Image, '/camera/edges', 10)\r\n\r\n        self.get_logger().info('Image processor initialized')\r\n\r\n    def image_callback(self, msg):\r\n        \"\"\"Process incoming camera image\"\"\"\r\n        try:\r\n            # Convert ROS Image to OpenCV\r\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\r\n\r\n            # Convert to grayscale\r\n            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\r\n\r\n            # Apply Canny edge detection\r\n            edges = cv2.Canny(gray, 100, 200)\r\n\r\n            # Convert back to ROS Image\r\n            edge_msg = self.bridge.cv2_to_imgmsg(edges, encoding='mono8')\r\n            edge_msg.header = msg.header  # Preserve timestamp\r\n\r\n            # Publish\r\n            self.edges_pub.publish(edge_msg)\r\n\r\n            self.get_logger().debug('Processed image, found edges')\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Failed to process image: {e}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = ImageProcessorNode()\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"laserscan-subscriber-with-obstacle-detection",children:"LaserScan Subscriber with Obstacle Detection"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"File"}),": ",(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/lidar_subscriber.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\"\"\"\r\nLiDAR LaserScan subscriber with obstacle detection\r\nSimulation environment: Gazebo 11+\r\n\"\"\"\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import LaserScan\r\nfrom std_msgs.msg import Float32\r\n\r\nclass ObstacleDetectorNode(Node):\r\n    def __init__(self):\r\n        super().__init__('obstacle_detector')\r\n        self.obstacle_threshold = 0.5  # meters\r\n\r\n        # Subscribe to LiDAR scan\r\n        self.scan_sub = self.create_subscription(\r\n            LaserScan,\r\n            '/scan',\r\n            self.scan_callback,\r\n            10)\r\n\r\n        # Publish minimum distance\r\n        self.min_distance_pub = self.create_publisher(Float32, '/obstacle/min_distance', 10)\r\n\r\n        self.get_logger().info('Obstacle detector initialized')\r\n\r\n    def scan_callback(self, msg):\r\n        \"\"\"Process incoming LiDAR scan\"\"\"\r\n        try:\r\n            # Filter out infinity values (no return)\r\n            valid_ranges = [r for r in msg.ranges if 0 < r < float('inf')]\r\n\r\n            if not valid_ranges:\r\n                self.get_logger().warn('No valid LiDAR readings')\r\n                return\r\n\r\n            # Find minimum range (closest obstacle)\r\n            min_range = min(valid_ranges)\r\n            min_index = msg.ranges.index(min_range)\r\n\r\n            # Calculate angle to closest obstacle\r\n            obstacle_angle = msg.angle_min + min_index * msg.angle_increment\r\n\r\n            # Publish minimum distance\r\n            min_dist_msg = Float32(data=float(min_range))\r\n            self.min_distance_pub.publish(min_dist_msg)\r\n\r\n            # Log obstacle warning if too close\r\n            if min_range < self.obstacle_threshold:\r\n                self.get_logger().warn(\r\n                    f'Obstacle detected! Distance: {min_range:.2f}m at angle {obstacle_angle:.2f}rad')\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Failed to process scan: {e}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = ObstacleDetectorNode()\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"imu-subscriber",children:"IMU Subscriber"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"File"}),": ",(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/imu_subscriber.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\"\"\"\r\nIMU subscriber for motion monitoring\r\nSimulation environment: Gazebo 11+\r\n\"\"\"\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Imu\r\nimport math\r\n\r\nclass IMUMonitorNode(Node):\r\n    def __init__(self):\r\n        super().__init__('imu_monitor')\r\n\r\n        # Subscribe to IMU\r\n        self.imu_sub = self.create_subscription(\r\n            Imu,\r\n            '/imu/data',\r\n            self.imu_callback,\r\n            10)\r\n\r\n        self.get_logger().info('IMU monitor initialized')\r\n\r\n    def imu_callback(self, msg):\r\n        \"\"\"Process incoming IMU data\"\"\"\r\n        try:\r\n            # Extract acceleration components\r\n            ax = msg.linear_acceleration.x\r\n            ay = msg.linear_acceleration.y\r\n            az = msg.linear_acceleration.z\r\n\r\n            # Extract angular velocity components\r\n            wx = msg.angular_velocity.x\r\n            wy = msg.angular_velocity.y\r\n            wz = msg.angular_velocity.z\r\n\r\n            # Calculate magnitudes\r\n            accel_mag = math.sqrt(ax**2 + ay**2 + az**2)\r\n            angular_mag = math.sqrt(wx**2 + wy**2 + wz**2)\r\n\r\n            # Log (debug level to avoid spam)\r\n            self.get_logger().debug(\r\n                f'Accel: {accel_mag:.2f} m/s\xb2, Angular: {angular_mag:.2f} rad/s')\r\n\r\n            # Detect significant acceleration\r\n            if accel_mag > 15.0:  # More than 1.5G\r\n                self.get_logger().warn(f'High acceleration detected: {accel_mag:.2f}m/s\xb2')\r\n\r\n            # Detect fast rotation\r\n            if angular_mag > 3.0:  # More than ~170 degrees/second\r\n                self.get_logger().warn(f'Fast rotation detected: {angular_mag:.2f} rad/s')\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Failed to process IMU data: {e}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = IMUMonitorNode()\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"multi-sensor-fusion-with-time-synchronization",children:"Multi-Sensor Fusion with Time Synchronization"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"File"}),": ",(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/sensor_fusion_node.py"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\r\n\"\"\"\r\nMulti-sensor fusion with time synchronization\r\nSimulation environment: Gazebo 11+\r\n\"\"\"\r\n\r\nimport rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, LaserScan, Imu\r\nfrom message_filters import Subscriber, ApproximateTimeSynchronizer\r\n\r\nclass SensorFusionNode(Node):\r\n    def __init__(self):\r\n        super().__init__('sensor_fusion')\r\n\r\n        # Create subscribers using message_filters\r\n        image_sub = Subscriber(self, Image, '/camera/image_raw')\r\n        scan_sub = Subscriber(self, LaserScan, '/scan')\r\n        imu_sub = Subscriber(self, Imu, '/imu/data')\r\n\r\n        # Synchronize messages within 100ms\r\n        ts = ApproximateTimeSynchronizer(\r\n            [image_sub, scan_sub, imu_sub],\r\n            queue_size=10,\r\n            slop=0.1)  # 100ms time window\r\n        ts.registerCallback(self.fusion_callback)\r\n\r\n        self.get_logger().info('Sensor fusion node initialized')\r\n\r\n    def fusion_callback(self, image_msg, scan_msg, imu_msg):\r\n        \"\"\"Process synchronized sensor data\"\"\"\r\n        try:\r\n            # Get image timestamp\r\n            image_time = image_msg.header.stamp.sec + image_msg.header.stamp.nanosec / 1e9\r\n\r\n            # Get LiDAR data\r\n            min_range = min([r for r in scan_msg.ranges if 0 < r < float('inf')])\r\n\r\n            # Get IMU acceleration\r\n            accel = imu_msg.linear_acceleration\r\n\r\n            self.get_logger().info(\r\n                f'Fused data - Time: {image_time:.3f}, MinRange: {min_range:.2f}m, '\r\n                f'Accel: {accel.x:.2f},{accel.y:.2f},{accel.z:.2f}')\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Fusion callback error: {e}')\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    node = SensorFusionNode()\r\n    try:\r\n        rclpy.spin(node)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        node.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"layer-2-ai-collaboration-notes",children:"Layer 2: AI Collaboration Notes"}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udcac ",(0,i.jsx)(n.strong,{children:"Prompt 1"}),": \"The LaserScan ranges include 'inf' values. What do they mean?\""]}),"\n",(0,i.jsx)(n.p,{children:"Claude explains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"inf"})," (infinity) = no laser return at that angle"]}),"\n",(0,i.jsx)(n.li,{children:"Object too far, light absorbed, or no object"}),"\n",(0,i.jsxs)(n.li,{children:["Always filter with: ",(0,i.jsx)(n.code,{children:"if 0 < r < float('inf')"})]}),"\n",(0,i.jsxs)(n.li,{children:["Simplifies to: ",(0,i.jsx)(n.code,{children:"if r > 0 and not math.isinf(r)"})]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udcac ",(0,i.jsx)(n.strong,{children:"Prompt 2"}),': "My synchronized callback never fires. What\'s wrong?"']}),"\n",(0,i.jsx)(n.p,{children:"Claude explains:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Time difference between messages > slop parameter"}),"\n",(0,i.jsx)(n.li,{children:"Check message update rates match approximately"}),"\n",(0,i.jsx)(n.li,{children:"If camera is 30 Hz and LiDAR is 10 Hz, timing is hard to sync"}),"\n",(0,i.jsxs)(n.li,{children:["Increase slop: ",(0,i.jsx)(n.code,{children:"slop=0.5"})," (500ms window) for slower sensors"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"problem-cv_bridge-not-found",children:'Problem: "cv_bridge not found"'}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": cv_bridge package not installed\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt install python3-cv-bridge\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-image-callback-receives-empty-image",children:"Problem: Image callback receives empty image"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Camera plugin not publishing or wrong topic name\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Verify topic exists and has messages\r\nros2 topic list | grep camera\r\nros2 topic hz /camera/image_raw\n"})}),"\n",(0,i.jsx)(n.h3,{id:"problem-laserscan-contains-all-inf-values",children:"Problem: LaserScan contains all inf values"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": No objects in LiDAR range or beam angle wrong\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Add objects to Gazebo world"}),"\n",(0,i.jsx)(n.li,{children:"Check ray sensor beam count (should be > 1)"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"problem-imu-data-looks-wrong-huge-random-values",children:"Problem: IMU data looks wrong (huge random values)"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Noise model too aggressive\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),": Reduce noise stddev in sensor plugin"]}),"\n",(0,i.jsx)(n.h3,{id:"problem-synchronized-callback-never-fires",children:"Problem: Synchronized callback never fires"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cause"}),": Message timestamps too far apart\r\n",(0,i.jsx)(n.strong,{children:"Solution"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Increase slop: ",(0,i.jsx)(n.code,{children:"ApproximateTimeSynchronizer(..., slop=0.5)"})]}),"\n",(0,i.jsx)(n.li,{children:"Verify all sensors publish at reasonable rates"}),"\n",(0,i.jsxs)(n.li,{children:["Check ROS 2 clock synchronization (",(0,i.jsx)(n.code,{children:"ros2 topic echo /clock"}),")"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"self-assessment-checklist",children:"Self-Assessment Checklist"}),"\n",(0,i.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I've written an image subscriber that receives camera frames"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I can convert ROS 2 Image to OpenCV and back"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I've applied edge detection or another image filter"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I've written a LaserScan subscriber and extracted distance data"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I can identify obstacles from LiDAR data"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I've written an IMU subscriber and interpret acceleration/rotation"]}),"\n",(0,i.jsxs)(n.li,{className:"task-list-item",children:[(0,i.jsx)(n.input,{type:"checkbox",disabled:!0})," ","I understand message_filters and can synchronize multiple sensor streams"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2 subscribers are the primary interface"}),": Get data via topics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"cv_bridge handles image conversion"}),": Image \u2194 OpenCV seamlessly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Always filter invalid data"}),": inf values, negative ranges, etc."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Message filtering synchronizes sensors"}),": Keep multi-sensor pipelines aligned"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Processing happens in callbacks"}),": Minimize compute per message"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"next-lesson",children:"Next Lesson"}),"\n",(0,i.jsx)(n.p,{children:"In Lesson 7, you'll close the loop by commanding robot motion based on processed sensor data."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"./lesson-07-gazebo-ros2-integration.md",children:"Go to Lesson 7: Gazebo-ROS 2 Integration \u2192"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Lesson Status"}),": Complete with four sensor processor examples (camera, LiDAR, IMU, fusion) and troubleshooting."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Duration"}),": 75 minutes (including RViz sensor visualization)"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Files Created"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/camera_subscriber.py"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/lidar_subscriber.py"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/imu_subscriber.py"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"examples/chapter-2-gazebo/lesson-06/sensor_fusion_node.py"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Concepts Covered"}),": 8 (Image subscribers, LaserScan subscribers, IMU subscribers, cv_bridge, message filtering, obstacle detection, edge detection, RViz visualization)"]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);